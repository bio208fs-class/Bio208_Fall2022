{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bio 208: Working with tabular data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas library\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a widely used Python library for working with tabular data.\n",
    "\n",
    "The usual convention that Pandas adopts when working with tabular data is one in which the rows of the data represent the \"cases\". \"observations\", or \"entities\" we're studying (e.g. individuals in a population, genomic features, geographical regions, etc) and the columns of the table represent the variables of interest that have been determined or measured or recorded for those cases or entities (e.g. gene identifiers, sequence length, measures of expression, etc). \n",
    "\n",
    "![Image from Pandas tutorial.](https://pandas.pydata.org/docs/_images/01_table_dataframe.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  # we'll import numpy as well, as it will be useful for calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames\n",
    "\n",
    "The core data structure in the Pandas library is called a \"data frame\" (`DataFrame`).\n",
    "\n",
    "We can create a dataframe by calling the `DataFrame` class with a dictionary in which the keys are the names of the columns, and the values are lists or arrays of the values in each column. This is illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Name\": [\"ORF1ab\", \"S\", \"E\", \"M\", \"N\", \"YFG1\"],\n",
    "    \"Start\": [266,  21563, 26245, 26523, 28274,99],\n",
    "    \"Stop\": [21555, 25384, 26472, 27191, 29533, 150],\n",
    "    \"Product\": [\"ORF1ab polyprotein\", \"surface glycoprotein\", \n",
    "                \"envelope protein\", \"membrane glycoprotein\",\n",
    "                \"nucleocapsid phosphoprotein\", pd.NA]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a DataFrame from a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we won't be creating DataFrames by hand but rather reading tabular data from files. Pandas include a variety of `read_*` functions such as `read_csv` and `read_excel` for reading such data. We'll primarily using `read_csv` in this class, to read tables delimited with either commas (\"comma separated values\" = `.csv` files) or tabs (\"tab separated values\" = `.tsv` files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a test spreadsheet I created in Excel durig our class session\n",
    "df2 = pd.read_table(\"/Users/pmagwene/Downloads/example-table.tsv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the names and types of the columns of the DataFrame. What are the dimensions (number of rows and columns) of the DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `len` function applied to a data frame gives the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a specific column from a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve a specific column of data from a DataFrame we can index the DataFrame with a string that gives the column name of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a column name would also be a valid Python variable name, there is a short-hand way to access columns, as if they were attributes of the DataFrame, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting specific rows from a DataFrame using slices\n",
    "\n",
    "When you index a DataFrame with an integer slice instead of a string, this returns the specified range of rows (obeying Python's standard 0-indexing conventions).  Not that row indexing like this requires a slice; a single integer index won't work with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:2]  # get the first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:1]  # to get the first row I still had to use the slice syntax; df[0] won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting  subset of rows and columns from a DataFrame\n",
    "\n",
    "If you want to simultaneously get a subset of rows and/or columns, you can use the `DataFrame.loc` (location) attribute. \n",
    "\n",
    "One subtle but important point about using `loc` is that when specifing the row slice, the labels correspond not to the integer position along the rows but rather the indexing labels.  When you create a DataFrame, you can specify a set of index labels for the rows.  If you don't specify such labels, Pandas will create a set of default indexing labels based on the integer positions.  This is what is being shown by the numbers in bold on the left margin of the data frames when we display them in this notebook.  The `loc` attribute allows us to create slices based on these row index labels, but these these index label slices differ from the positional slices in that they are inclusive (both start and stop labels are included).  I'll do my best to illustrate how this works below with some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see how to get a specific subset of rows and columns using `loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows with the index labels 3 and 1, and columns \"Product\" and \"Start\"\n",
    "df.loc[[3, 1], [\"Product\",\"Start\"]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slice ranges of rows and columns using `loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all rows, columns from Name to Stop\n",
    "df.loc[:, \"Name\":\"Stop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if we specify a slice on the rows, notice how it uses the label indices on the left to specify what rows to take, and also notice that the slice is inclusive of the last specified row (if this was instead based on Python's standard positional indexing the statement below would be expected to return only two rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:3, [\"Name\",\"Product\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subtleties of row-indexing with `loc` become particularly apparent if we create a version of the table in which we've reversed the row order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reversed = df[::-1]  # get the rows in reversed order\n",
    "df_reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this reversed version of the data frame, the same slice syntax we used above doesn't work because the row label indices are no longer in the order 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an empty data frame because the label indices 1:3 won't work\n",
    "df_reversed.loc[1:3, [\"Name\", \"Product\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However specifying the slice range as `3:1` works because that is consistent with the order of labelled indices in `df_reversed`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an empty data frame because the label indices 1:3 won't work\n",
    "df_reversed.loc[3:1, [\"Name\", \"Product\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting cross sections of a DataFrame by integer positions using `DataFrame.iloc`\n",
    "\n",
    "`DataFrame.iloc` eanbles conventional indexing of both rows and columns by integer position, as illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:3, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,2]  # value in the first row, third column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[2,0],[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reversed.iloc[1:3, [0,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new columns by computing on existing columns\n",
    "\n",
    "DataFrames support a simple syntax for creating new columns from existing ones.  Like numpy arrays, most operations with data frame columns work element-by-element so we can calculate new variables of interest from existing ones by applying functions or operations to one or more of the variables.\n",
    "\n",
    "Here I show how to create a new column \"Length\" by subtracting the Start coordinates from each of the Stop coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Length\"] = df.Stop - df.Start + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting the rows of a DataFrame by Boolean indexing\n",
    "\n",
    "When working with large data sets, we frequently want to explore how variables of interest differ across different subsets of the cases.  Pandas (and Numpy) facilitate this sort of analysis by allowing us to subset rows of a DataFrame using Boolean indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this we'll look at ways to subset our small data frame to get at genes that meet certain criteria.\n",
    "\n",
    "The COVID-19 genome is about 30 Kbp in length.  Consider the case where we want to find only those genes towards the \"right\" end of the genome (i.e. with respect to the arbitrary coordinate system the reference genome has been assigned is reported).  One way to do this would be to find all those genes for which the \"Start\" value is greater than some cutoff, say 25,000.\n",
    "\n",
    "Let's see what happens when we compare each of the values (rows) in the \"Start\" column and asks whether the corresponding value is greater than 25000.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Start > 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, we get back a column (Series) of Boolean (True/False) values indicating for which of the corresponding elements the comparison is True.\n",
    "\n",
    "Since that statement return a Boolean series, we can use it directly to index the rows of our data frame. You might find it useful to read think about the following Python case as saying \"df where df.Start is greater than 25000\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Start > 25000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean indexing like this creates a new DataFrame, which we'd typically we'd assign to a variable so would do further computations with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endgenes = df[df.Start > 25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endgenes.loc[:,[\"Name\",\"Product\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complex subsetting using Boolean operators\n",
    "\n",
    "Pandas defines the logical operators `&` (and) and `|` (or) for working with Boolean Series.  For example, the following returns a Boolean Series corresponding to the rows of our data frame where the start position was greater than 25,000 and the gene length was greater than 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_and_long = (df.Start > 25000) & (df.Length > 500)\n",
    "end_and_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the final result is a single Boolean series which we can use to filter or subset the rows of our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[end_and_long]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating plots from DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generating plots from data in Pandas DataFrames you can pass variables of interest to the respective `matplotlib` functions or use plotting attributes associated with the DataFrame object (which in turn uses matplotlib as it's backend).  I illustrate both approaches below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a histogram of genes Lengths\n",
    "plt.hist(df.Length)\n",
    "\n",
    "pass # adding pass here prevents the data objects returned from \n",
    "     # plt.hist from being printed in the output. This is just to make\n",
    "     # the notebook output look neat and tidy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `plot` attribute associated with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Length.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics from DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical columns in DataFrame support built-in methods for calculating summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Length.mean()  # average length of the genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Length.median() # median length of the genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Length.describe()  # mulitiple summary statistics about the values in the Length column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a table of features from the Saccharomyces Genome Database (SGD)\n",
    "\n",
    "The file [`SGD_features.tsv`](https://github.com/bio208fs-class/bio208fs-lecture/raw/master/data/SGD_features.tsv) is a tab-delimited file I downloaded from SGD that summarizes key pieces of information about genome features in the budding yeast genome.  The original file can be found here: http://sgd-archive.yeastgenome.org/curation/chromosomal_feature/\n",
    "\n",
    "Here's a short summary of the contents of this file, from the \"SGD_features.README\" document:\n",
    "\n",
    "```\n",
    "1. Information on current chromosomal features in SGD, including Dubious ORFs. \n",
    "Also contains coordinates of intron, exons, and other subfeatures that are located within a chromosomal feature.\n",
    "\n",
    "2. The relationship between subfeatures and the feature in which they\n",
    "are located is identified by the feature name in column #7 (parent\n",
    "feature). For example, the parent feature of the intron found in\n",
    "ACT1/YFL039C will be YFL039C. The parent feature of YFL039C is\n",
    "chromosome 6.\n",
    "\n",
    "3. The coordinates of all features are in chromosomal coordinates.\n",
    "\n",
    "Columns within SGD_features.tab:\n",
    "\n",
    "1.   Primary SGDID (mandatory)\n",
    "2.   Feature type (mandatory)\n",
    "3.   Feature qualifier (optional)\n",
    "4.   Feature name (optional)\n",
    "5.   Standard gene name (optional)\n",
    "6.   Alias (optional, multiples separated by |)\n",
    "7.   Parent feature name (optional)\n",
    "8.   Secondary SGDID (optional, multiples separated by |)\n",
    "9.   Chromosome (optional)\n",
    "10.  Start_coordinate (optional)\n",
    "11.  Stop_coordinate (optional)\n",
    "12.  Strand (optional)\n",
    "13.  Genetic position (optional)\n",
    "14.  Coordinate version (optional)\n",
    "15.  Sequence version (optional)\n",
    "16.  Description (optional)\n",
    "\n",
    "Note that \"chromosome 17\" is the mitochondrial chromosome.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [`SGD_features.tsv`](https://github.com/bio208fs-class/bio208fs-lecture/raw/master/data/SGD_features.tsv) to your computer and then load it using the `read_csv` function, specifying the delimiter argument as a tab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"/Users/pmagwene/Downloads/SGD_features.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the dimensions of this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the columns names and data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many genome features are there in the  yeast genome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the different feature types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.Type.unique()  # gives unique elements in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features.Type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the chromosome designations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.Chromosome.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new column - Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using np.abs here because for some of the features Start > Stop\n",
    "# The +1 accounts for the fact that the start/stop coordinates are inclusive\n",
    "features[\"Length\"] = np.abs(features.Stop - features.Start) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.Length.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram showing distribution of lengths of features\n",
    "features.Length.plot.hist(bins=100)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How  many of those features are annotated as \"ORFs\" (open reading frames)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs = features[features.Type == \"ORF\"]\n",
    "len(orfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting ORFs based on their length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.sort_values(\"Length\").loc[:,[\"SGDID\", \"Chromosome\",\n",
    "                                  \"Gene\",\"Length\",\"Description\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in descending order\n",
    "orfs.sort_values(\"Length\", ascending=False).loc[:,[\"SGDID\", \"Chromosome\",\n",
    "                                                   \"Gene\",\"Length\",\"Description\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Chromosome data type from object to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 2-micron from consideration\n",
    "orfs = orfs[orfs.Chromosome != \"2-micron\"].copy() \n",
    "\n",
    "# we use copy above because we're going to make some modifications of the ORF data\n",
    "# so we want an independent copy of the data not a \"view\" into the features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.loc[:,\"Chromosome\"] = pd.to_numeric(orfs.Chromosome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.Chromosome.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of ORF lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(orfs.Length, bins=100)\n",
    "plt.xlabel(\"Gene length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since lengths differ by several orders of magnitude, a log-transform might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(orfs.Length),bins = 100)\n",
    "plt.xlabel(\"log10(Gene length)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the ORFS are designated as \"Dubious\"? How many are \"Verified\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubious = orfs[orfs.Qualifier == \"Dubious\"]\n",
    "len(dubious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified = orfs[orfs.Qualifier == \"Verified\"]\n",
    "len(verified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of length of dubious ORFs? What is the distribution of lengths of verified ORFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(verified.Length, alpha=0.5, bins=np.arange(0,12000,100))\n",
    "plt.hist(dubious.Length, alpha=0.5, bins=np.arange(0,12000,100))\n",
    "\n",
    "# add labels\n",
    "plt.xlabel(\"ORF length (bp)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubious.Length.median(), verified.Length.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we're looking at the the log10 of the frequencies NOT the lengths\n",
    "\n",
    "# generate histograms\n",
    "plt.hist(verified.Length, color='red', alpha=0.35, bins=np.arange(0,12000,100),log=True)\n",
    "plt.hist(dubious.Length, color='black', alpha=0.35, bins=np.arange(0,12000,100), log=True)\n",
    "\n",
    "# add dashed lines representing median lengths\n",
    "plt.vlines(dubious.Length.median(), ymin=0, ymax=400, color='black', linestyle=\"dashed\")\n",
    "plt.vlines(verified.Length.median(), ymin=0, ymax=400, color='red', linestyle=\"dashed\")\n",
    "\n",
    "# add labels\n",
    "plt.xlabel(\"ORF length (bp)\")\n",
    "plt.ylabel(\"Log10(Frequency)\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dubious + Verified is not the full set of ORFS. What are the other Qualifier values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.Qualifier.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using groupby to get a breakdown of ORFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.groupby(\"Qualifier\").Qualifier.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.Qualifier.value_counts()  # short hand for counting things in categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the groupby method to calculate aggregate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.groupby(\"Qualifier\").Length.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs.groupby([\"Chromosome\", \"Qualifier\"]).Qualifier.count().head(6)\n",
    "# table continues on but I just took the first six values to truncate output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations of Chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chromosome length data\n",
    "chroms = pd.read_csv(\"/Users/pmagwene/Downloads/chromosome_length.tsv\", \n",
    "                     delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the ORFS on a single chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot chromosome 1\n",
    "plt.barh(1, chroms.Length[chroms.Chromosome == 1], height=0.25, color='steelblue')\n",
    "\n",
    "chr01orfs = orfs[orfs.Chromosome == 1]\n",
    "\n",
    "for (start, stop) in zip(chr01orfs.Start, chr01orfs.Stop):\n",
    "    left = min(start, stop)\n",
    "    width = abs(stop - start)\n",
    "    plt.barh(1, width, left=left, color='orange', height=0.35)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Position (bp)\")\n",
    "plt.ylabel(\"Chromosome\")\n",
    "    \n",
    "# specify specific y-axis scaling to make this look nice\n",
    "plt.ylim(0,2)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot chromosome 1 and 2 orfs\n",
    "\n",
    "plt.barh(1, chroms.Length[chroms.Chromosome == 1], height=0.25, color='steelblue')\n",
    "plt.barh(2, chroms.Length[chroms.Chromosome == 2], height=0.25, color='steelblue')\n",
    "\n",
    "focalorfs = orfs[orfs.Chromosome.isin([1,2])]\n",
    "\n",
    "for (chrom, start, stop) in zip(focalorfs.Chromosome, focalorfs.Start, focalorfs.Stop):\n",
    "    left = min(start, stop)\n",
    "    width = abs(stop - start)\n",
    "    plt.barh(chrom, width, left=left, color='orange', height=0.35)\n",
    "    \n",
    "plt.xlabel(\"Position (bp)\")\n",
    "plt.ylabel(\"Chromosome\")\n",
    "    \n",
    "# specify specific y-axis scaling to make this look nice\n",
    "plt.ylim(0,3)\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dba143bd142596631d326db5de1f37801741131ac6acc925c40f37283976f2d3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
